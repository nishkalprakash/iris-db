{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "065f6ac7",
   "metadata": {},
   "source": [
    "# Create a structured database for the Iris dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d787a8",
   "metadata": {},
   "source": [
    "### Common Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b0073f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% lib.py\n",
    "# from json import load, dumps\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "## Logger setup\n",
    "import logging\n",
    "pymongo_logger = logging.getLogger('pymongo')\n",
    "# Set its level to WARNING to silence INFO and DEBUG messages\n",
    "pymongo_logger.setLevel(logging.WARNING)\n",
    "class LoggerManager:\n",
    "    \"\"\"Singleton Logger Manager for consistent logging across the app.\"\"\"\n",
    "    _logger = None\n",
    "\n",
    "    @classmethod\n",
    "    def get_logger(cls, log_dir=\"logs/\", name=__name__, level=\"DEBUG\"):\n",
    "        if cls._logger is None:\n",
    "            log_dir = Path(log_dir)\n",
    "            log_dir.mkdir(exist_ok=True)\n",
    "            log_file = log_dir / f\"{name}.log\"\n",
    "            logging.basicConfig(\n",
    "                level=logging.DEBUG,\n",
    "                # also log the calling function name\n",
    "                format='%(asctime)s - %(name)s - %(funcName)s - %(levelname)s - %(message)s',\n",
    "                # datefmt='%Y-%m-%d %H:%M:%S',\n",
    "                handlers=[\n",
    "                    logging.FileHandler(log_file, encoding=\"utf-8\"),\n",
    "                    logging.StreamHandler()\n",
    "                ]\n",
    "            )\n",
    "            # set logging level\n",
    "            if isinstance(level, str):\n",
    "                level = getattr(logging, level.upper(), logging.INFO)\n",
    "            cls._logger = logging.getLogger(name)\n",
    "            cls._logger.setLevel(level)\n",
    "        return cls._logger\n",
    "\n",
    "import shutil\n",
    "class FileManager:\n",
    "    \"\"\"Singleton File Manager for consistent file operations.\"\"\"\n",
    "    _instance = None\n",
    "    lg = LoggerManager.get_logger(__name__)\n",
    "    def __new__(cls):\n",
    "        if cls._instance is None:\n",
    "            cls._instance = super(FileManager, cls).__new__(cls)\n",
    "        return cls._instance\n",
    "\n",
    "    # @staticmethod\n",
    "    # def load_json_file(filename):\n",
    "    #     \"\"\"Load and return data from a JSON file.\"\"\"\n",
    "    #     with open(filename, 'r') as file:\n",
    "    #         return load(file)\n",
    "\n",
    "    # @staticmethod\n",
    "    # def write_json_file(filename, data):\n",
    "    #     \"\"\"Write data to a JSON file.\"\"\"\n",
    "    #     with open(filename, 'w') as file:\n",
    "    #         file.write(dumps(data, indent=4, ensure_ascii=False))\n",
    "    \n",
    "    # @staticmethod\n",
    "    def read_creds(self,filename=\"mongo_creds.txt\"):\n",
    "        \"\"\"Read MongoDB credentials from a file using pathlib\"\"\"\n",
    "        \n",
    "        if not Path(filename).exists():\n",
    "            _ERROR_MSG = f\"Credentials file {filename} does not exist.Please create a mongo_creds.txt with user:passwd\"\n",
    "            self.lg.error(_ERROR_MSG)\n",
    "            raise FileNotFoundError(_ERROR_MSG)\n",
    "        user, passwd = Path(filename).read_text().strip().split(\":\")\n",
    "        self.lg.debug(\"MongoDB credentials loaded successfully.\")\n",
    "        return user, passwd\n",
    "    \n",
    "    # @staticmethod\n",
    "    def ensure_exists(self,path):\n",
    "        # check if path is Path() type if not make it\n",
    "        if not isinstance(path, Path):\n",
    "            path = Path(path)\n",
    "        if not path.exists():\n",
    "            path.mkdir(parents=True, exist_ok=True)\n",
    "        self.lg.debug(f\"Ensured directory exists: {path}\")\n",
    "    \n",
    "    # @staticmethod\n",
    "    def copy_file(self, src, dest, overwrite=False):\n",
    "        if isinstance(dest, str):\n",
    "            dest = Path(dest)\n",
    "        if not overwrite and dest.exists():\n",
    "            self.lg.info(f\"File {dest} already exists. Skipping copy.\")\n",
    "            return\n",
    "        self.ensure_exists(dest.parent)\n",
    "        shutil.copy2(src, dest)\n",
    "        self.lg.info(f\"Copied file from {src} to {dest}\")\n",
    "\n",
    "\n",
    "\n",
    "#%% Testing\n",
    "# lg.WARNING\n",
    "# import LoggerManager as lm\n",
    "# logging.WARNING\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e399ccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "from pathlib import Path\n",
    "# from lib import LoggerManager as lm, FileManager as fm, logging\n",
    "lm=LoggerManager()\n",
    "fm=FileManager()\n",
    "# TODO: move common imports to vars\n",
    "# sys.path.append(str(Path(__file__).parent))\n",
    "# from vars import *\n",
    "\n",
    "from pymongo import MongoClient, ASCENDING\n",
    "from pymongo.collection import Collection\n",
    "DB_BASE_ = Path(\"~/datasets/iris_db/\").expanduser()\n",
    "fm.ensure_exists(DB_BASE_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dbdd6f",
   "metadata": {},
   "source": [
    "### Copying to structured folder and adding to mongodb as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f4dad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_ID = \"CASIA_v1\"\n",
    "DS_NAME_ = Path(DS_ID)\n",
    "DS_BASE_ = DB_BASE_ / DS_NAME_\n",
    "fm.ensure_exists(DS_BASE_)\n",
    "\n",
    "ORIG_DB_BASE_ = Path(\"~/datasets/iris_datasets/CASIA/V1/CASIA-IrisV1/CASIA-IrisV1/CASIA Iris Image Database (version 1.0)\").expanduser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# insert into db\n",
    "\n",
    "metadata_casia_v1 = {\n",
    "    \"ds_id\": DS_ID,\n",
    "    \"name\": \"CASIA-IrisV1\",\n",
    "    \"db_info\": {\n",
    "        \"desc\": \"\"\"CASIA Iris Image Database Version 1.0 (CASIA-IrisV1) includes 756 iris images\n",
    "        from 108 eyes. For each eye, 7 images are captured in two sessions with our\n",
    "        self-developed device CASIA close-up iris camera (Fig.1), where three samples are\n",
    "        collected in the first session (Fig.2(a)) and four in the second session (Fig.2(b)). All\n",
    "        images are stored as BMP format with resolution 320*280\n",
    "        In order to protect our IPR in the design of our iris camera (especially the NIR\n",
    "        illumination scheme), the pupil regions of all iris images in CASIA-IrisV1 were\n",
    "        automatically detected and replaced with a circular region of constant intensity to\n",
    "        mask out the specular reflections from the NIR illuminators. Such editing\n",
    "        clearly makes iris boundary detection much easier but has minimal or no effects on\n",
    "        other components of an iris recognition system, such as feature extraction and\n",
    "        classifier design.\n",
    "        It is suggested that you compare two samples from the same eye taken in different\n",
    "        sessions when you want to compute the within-class variability. For example, the iris\n",
    "        images in the first session can be employed as training dataset and those from the\n",
    "        second session are used for testing.\n",
    "        \"\"\",\n",
    "        \"capture_device\": \"CASIA close-up iris camera\",\n",
    "        \"environment\": \"Indoor, controlled lighting\",\n",
    "        \"type\":\"NIR\",\n",
    "        \"notes\":\"\",\n",
    "        \"periocular\":False\n",
    "    },\n",
    "    # \"db_specs\":{\n",
    "    \"num_images\": 756,\n",
    "    \"num_people\": 108,\n",
    "    \"num_eyes\": 108,\n",
    "    \"num_eyes_per_person\": 1,\n",
    "    \"num_samples_per_eye\": 7,\n",
    "    \"num_sessions\": 2,\n",
    "    # },\n",
    "    'img_specs':{\n",
    "        \"ext\": \".bmp\",\n",
    "        \"res\": \"320x280\",\n",
    "        \"width\": 320,\n",
    "        \"height\": 280\n",
    "    },\n",
    "    'paths':{\n",
    "        'orig_base_': str(ORIG_DB_BASE_),\n",
    "        'base_': str(DS_BASE_),\n",
    "    },\n",
    "    'injested_at': datetime.now()\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04f2a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an unqiue index with ds_id\n",
    "# coll.create_index([(\"ds_id\", ASCENDING)], unique=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a1e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class IRIS_DB:\n",
    "#     def __init__(self, mongo_db_name=MONGO_DB_NAME, mongo_colleciton=META_COLL):\n",
    "#         self.conn = MongoClient(DB_IP, username=\"admin\", password=\"Temppass@123\", authSource=\"admin\")[mongo_db_name][db_name]\n",
    "\n",
    "#     def insert_metadata(self, metadata):\n",
    "#         self.conn.insert_one(metadata)\n",
    "\n",
    "#     def find_metadata(self, ds_id):\n",
    "#         return self.conn.find_one({\"ds_id\": ds_id})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406252c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# class IrisMeta:\n",
    "#     \"\"\"Class to handle operations related to the meta collection.\"\"\"\n",
    "#     def __init__(self, iris_db):\n",
    "#         if not isinstance(iris_db, IrisDB):\n",
    "#             raise ValueError(\"iris_db must be an instance of IrisDB\")\n",
    "#         self.iris_db = iris_db\n",
    "#         self.coll = iris_db.get_meta_coll()\n",
    "\n",
    "#     def get_all_metadata(self):\n",
    "#         \"\"\"Fetch all metadata documents from the meta collection.\"\"\"\n",
    "#         return list(self.coll.find({}, {'_id': 0}))\n",
    "\n",
    "#     def get_metadata(self, ds_id):\n",
    "#         \"\"\"Fetch metadata for a specific dataset ID.\"\"\"\n",
    "#         return self.coll.find_one({'ds_id': ds_id}, {'_id': 0})\n",
    "\n",
    "#     def update_metadata(self, metadata):\n",
    "#         \"\"\"Update or insert metadata document based on ds_id.\"\"\"\n",
    "#         if 'ds_id' not in metadata:\n",
    "#             raise ValueError(\"Metadata must contain 'ds_id' field.\")\n",
    "#         self.iris_db.update_one(metadata, key='ds_id', collection=self.coll)\n",
    "#         lg.info(f\"Metadata for ds_id '{metadata['ds_id']}' updated/inserted.\")\n",
    "#         return True\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a070af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## USAGE of IrisMeta\n",
    "\n",
    "# # ```python\n",
    "# # with IrisDB() as iris_db:\n",
    "# #     iris_meta = IrisMeta(iris_db)\n",
    "# #     all_metadata = iris_meta.get_all_metadata()\n",
    "# #     specific_metadata = iris_meta.get_metadata(\"some_ds_id\")\n",
    "# #     iris_meta.update_metadata({\"ds_id\": \"some_ds_id\", \"new_field\": \"value\"})\n",
    "# # ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cebee8",
   "metadata": {},
   "source": [
    "## IrisDB Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd30080c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup logging\n",
    "from functools import lru_cache\n",
    "from difflib import get_close_matches\n",
    "\n",
    "from time import sleep\n",
    "# logger = LoggerManager.get_logger(name=Path(__file__).stem)\n",
    "lg = lm.get_logger(__name__,level=\"DEBUG\")\n",
    "# lg = lm.get_logger(__name__,level=\"INFO\")\n",
    "# set log level to info\n",
    "# lg.setLevel(logging.DEBUG)\n",
    "\n",
    "class IrisDB:\n",
    "    \"\"\"\n",
    "    In: None\n",
    "    Out: IrisDB Object that can be used to connect to a particular db\n",
    "    param: \n",
    "        ds_id - name of the dataset collection\n",
    "    \"\"\"\n",
    "    DB_IP = 'localhost'\n",
    "    DB_NAME = 'iris_db'\n",
    "    META_COLL_NAME = 'meta'\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        ds_id=None,\n",
    "        db_ip=None, \n",
    "        mongo_db_name=None, \n",
    "        meta_coll_name=None\n",
    "        # db_coll=None, # this could be used to shortcircuit the process?\n",
    "        ) -> object:\n",
    "        self.db_ip = self.DB_IP if db_ip is None else db_ip\n",
    "        self.mongo_db_name = self.DB_NAME if mongo_db_name is None else mongo_db_name\n",
    "        self.meta_coll_name = self.META_COLL_NAME if meta_coll_name is None else meta_coll_name\n",
    "        # self.db_coll = DB_COLL if db_coll is None else db_coll\n",
    "        ## get user:passwd from mongo_creds.txt file\n",
    "        user,passwd = fm.read_creds()\n",
    "        self._mongo_admin_user = user\n",
    "        self._mongo_admin_password = passwd\n",
    "        self.closing = False\n",
    "        if ds_id is not None:\n",
    "            self.connect(ds_id)\n",
    "        # set it have the same properties as Collection class\n",
    "        \n",
    "    @property\n",
    "    @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    def mongo_client(self):\n",
    "        \"\"\"Lazily creates and returns the MongoClient instance.\"\"\"\n",
    "        if self.closing:\n",
    "            delattr(self, 'mongo_client')\n",
    "            return None\n",
    "        lg.debug(\"MongoDB client is not initialized. Creating client...\")\n",
    "        mc = MongoClient(\n",
    "            self.db_ip,\n",
    "            username=self._mongo_admin_user,\n",
    "            password=self._mongo_admin_password,\n",
    "            authSource=\"admin\"\n",
    "        )\n",
    "        lg.debug(\"MongoDB client created successfully.\")\n",
    "        return mc\n",
    "    \n",
    "\n",
    "    @property\n",
    "    @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    def mongo_db(self):\n",
    "        \"\"\"Lazily creates and returns the Database object using the client.\"\"\"\n",
    "        if self.closing:\n",
    "            delattr(self, 'mongo_db')\n",
    "            return None\n",
    "        lg.debug(\"Establishing MongoDB database connection...\")\n",
    "        # This will automatically trigger the mongo_client property if needed\n",
    "        conn = self.mongo_client[self.mongo_db_name]\n",
    "        lg.debug(\"MongoDB connection established successfully.\")\n",
    "        return conn\n",
    "    \n",
    "    @property\n",
    "    @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    def meta_coll(self):\n",
    "        \"\"\"Lazily creates and returns the Meta collection using the client.\"\"\"\n",
    "        coll = self.mongo_db[self.meta_coll_name]\n",
    "        lg.debug(\"Returned meta collection.\")\n",
    "        return coll\n",
    "\n",
    "    @property\n",
    "    @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    def avail_ds(self) -> set:\n",
    "        \"\"\"Lazily creates and returns the set of available iris_db from meta coll using the mongo client.\"\"\"\n",
    "        lg.debug(\"Connecting to meta db to find avail ds\")\n",
    "        # This will automatically trigger the mongo_client property if needed\n",
    "        try:\n",
    "            avail_ds = {i['ds_id'] for i in self.meta_coll.find({}, {'_id': 0, 'ds_id': 1})}\n",
    "        except Exception as e:\n",
    "            lg.error(f\"Error fetching available datasets: {e}\")\n",
    "            raise e\n",
    "        avail_ds.add(self.meta_coll_name)\n",
    "        # print(avail_ds)\n",
    "        lg.debug(f\"Fetched List of avail databases -> {avail_ds}\")\n",
    "        return avail_ds\n",
    "\n",
    "    def get_avail_ds(self) -> set:\n",
    "        \"\"\"Get a set of available IRIS ds_id.\"\"\"\n",
    "        print(f\"Avail Datasets: {self.avail_ds}\")\n",
    "        return self.avail_ds\n",
    "    get_datasets = get_ds = list_ds = get_avail_ds = get_avail_ds\n",
    "    \n",
    "    # @property\n",
    "    # @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    # def coll(self):\n",
    "    #     \"\"\"Lazily creates and returns the collection object using the database.\"\"\"\n",
    "    #     if self.closing:\n",
    "    #         delattr(self, 'coll')\n",
    "    #         return None\n",
    "    #     lg.debug(\"Establishing MongoDB collection connection...\")\n",
    "    #     # This will automatically trigger the mongo_db property if needed\n",
    "    #     coll = self.mongo_db[self.ds_name]\n",
    "    #     lg.debug(\"MongoDB collection connection established successfully.\")\n",
    "    #     return coll\n",
    "\n",
    "    def find_ds(self, ds_id, avail_ds=None, acc=0.4, count=1) -> str|set:\n",
    "        # 1. Create a mapping from lowercase name to original name.\n",
    "        mapping = {db.lower(): db for db in (avail_ds or self.avail_ds)}\n",
    "        # 2. Get the lowercase versions of all available DBs for matching.\n",
    "        lower_avail_ds = list(mapping.keys())\n",
    "        # 3. Perform the match on the lowercase versions.\n",
    "        matches = get_close_matches(ds_id.lower(), lower_avail_ds, n=count, cutoff=acc)\n",
    "        # 4. If a match is found, use the mapping to return the original name.\n",
    "        if matches:\n",
    "            if count > 1:\n",
    "                res = {mapping[match] for match in matches}\n",
    "            else:\n",
    "                res = mapping[matches[0]]\n",
    "            msg = f\"Found matches for {ds_id}: {res}\"\n",
    "            print(msg)\n",
    "            lg.debug(msg)\n",
    "            return res\n",
    "        return None\n",
    "\n",
    "    # @lru_cache(maxsize=None) # Caches the result after the first call\n",
    "    def set_meta_primary(self):\n",
    "        \"\"\"Get the meta collection\"\"\"\n",
    "        lg.debug(\"Accessing meta collection...\")\n",
    "        self.ds_id = self.meta_coll_name\n",
    "        self.coll = self.meta_coll\n",
    "        return self.meta_coll\n",
    "    meta_connect = set_meta_primary\n",
    "\n",
    "    # def meta_connect(self):\n",
    "    #     \"\"\"Connect to the meta collection\"\"\"\n",
    "    #     lg.info(\"Connecting to meta collection...\")\n",
    "    #     return self.meta_coll\n",
    "\n",
    "    def connect(self, ds_id, acc=0.4) -> Collection:\n",
    "        \"\"\"Will connect to the database into a given collection\n",
    "        It sets the self.ds_id attrib and self.coll\n",
    "        \"\"\"\n",
    "        # if meta is tring to be connected then return the meta collection\n",
    "        # if ds_id == self.meta_coll_name:\n",
    "        #     self.ds_id = self.meta_coll_name\n",
    "        #     # self.coll = self.get_meta_coll()\n",
    "        #     lg.info(f\"Connecting to {ds_id} Collection\")\n",
    "        #     return self.meta_coll\n",
    "        \n",
    "        avail_ds = self.avail_ds\n",
    "        if (closest_match := self.find_ds(ds_id=ds_id, avail_ds=avail_ds, acc=acc)):\n",
    "            self.ds_id = closest_match\n",
    "            lg.info(f\"Connecting to {self.ds_id} Collection\")\n",
    "            # self.ds_prefix=Path(DS_PREFIX)\n",
    "            # self.ds_path=self.ds_prefix/self.ds_id\n",
    "        else:\n",
    "            lg.error(f\"{ds_id} Collection Not found in available datasets. List: {avail_ds}\")\n",
    "            return None\n",
    "        self.coll = self.mongo_db[self.ds_id]\n",
    "        return self.coll\n",
    "    get_coll = connect\n",
    "\n",
    "    # def determine_coll(self,collection=None):\n",
    "    #     if collection is None:\n",
    "    #         if self.ds_id == self.meta_coll_name:\n",
    "    #             collection = self.meta_coll\n",
    "    #         else:\n",
    "    #             collection = self.coll\n",
    "    #     return collection\n",
    "        \n",
    "    def update(self, doc, key = None, coll=None):\n",
    "        \"\"\"Update a single document in the connected collection\"\"\"\n",
    "        if '_id' in doc:\n",
    "            key = '_id'\n",
    "        if key is None:\n",
    "            key = 'ds_id'\n",
    "        if coll is None:\n",
    "            coll = self.coll\n",
    "        res=coll.update_one({key: doc[key]}, {'$set': doc}, upsert=False)\n",
    "        lg.info(f\"Updated document in {self.ds_id} collection.\")\n",
    "        return res\n",
    "    \n",
    "    def insert(self, docs, coll = None):\n",
    "        if coll is None:\n",
    "            coll = self.coll\n",
    "        try:\n",
    "            if isinstance(docs, dict):\n",
    "                res = coll.insert_one(docs)\n",
    "            elif isinstance(docs, list):\n",
    "                # ignore if duplicate key error\n",
    "                res = coll.insert_many(docs, ordered=False)\n",
    "        except Exception as e:\n",
    "            lg.error(f\"Error inserting document into {self.ds_id} collection: {e}\")\n",
    "            res = None\n",
    "        lg.info(f\"Inserted document(s) into {self.ds_id} collection.\")\n",
    "        return res\n",
    "\n",
    "    ## feature to get a Mongo Collection by getitem on iris_db object\n",
    "    def __getitem__(self, coll_name):\n",
    "        \"\"\"Get a MongoDB collection by name\"\"\"\n",
    "        # if not hasattr(self, 'mongo_conn'):\n",
    "            # lg.error(\"No MongoDB connection established.\")\n",
    "            # return None\n",
    "        return self.get_coll(coll_name)\n",
    "\n",
    "    # def find(self, query, proj=None, collection=None):\n",
    "    #     \"\"\"Get data from the connected collection\"\"\"\n",
    "    #     if collection is None:\n",
    "    #         if not hasattr(self, 'coll'):\n",
    "    #             lg.error(\"No collection connected. Please call connect() first.\")\n",
    "    #             return None\n",
    "    #         collection = self.coll\n",
    "\n",
    "    #     return collection.find(query, proj)\n",
    "\n",
    "    # def update_one(self, doc, key=None, collection=None):\n",
    "    #     \"\"\"Update a single document in the connected collection\"\"\"\n",
    "    #     if not hasattr(self, 'coll'):\n",
    "    #         lg.error(\"No collection connected. Please call connect() first.\")\n",
    "    #         return None\n",
    "    #     if collection is None:\n",
    "    #         collection = self.coll\n",
    "    #     if key is None:\n",
    "    #         if '_id' in doc:\n",
    "    #             key = '_id'\n",
    "    #         elif self.ds_name=='meta' and 'ds_id' in doc:\n",
    "    #             key = 'ds_id'\n",
    "    #         else:\n",
    "    #             raise ValueError(\"No valid key found for document.\")\n",
    "    #     if key in doc:\n",
    "    #         collection.update_one({key: doc[key]}, {'$set': doc}, upsert=True)\n",
    "    #     else:\n",
    "    #         raise ValueError(f\"Key '{key}' not found in document.\")\n",
    "    #     lg.info(f\"Updated document in {self.ds_name} collection.\")\n",
    "    #     return True\n",
    "    \n",
    "    # def update_many(self, docs, key=None):\n",
    "    #     \"\"\"Update data in the connected collection\"\"\"\n",
    "    #     if not hasattr(self, 'coll'):\n",
    "    #         lg.error(\"No collection connected. Please call connect() first.\")\n",
    "    #         return None\n",
    "    #     if isinstance(docs, dict):\n",
    "    #         docs = [docs]\n",
    "    #     for doc in docs:\n",
    "    #         if key is None:\n",
    "    #             if '_id' in doc:\n",
    "    #                 key = '_id'\n",
    "    #             elif self.ds_name=='meta' and 'ds_id' in doc:\n",
    "    #                 key = 'ds_id'\n",
    "    #             else:\n",
    "    #                 raise ValueError(\"No valid key found for document.\")\n",
    "    #         if key in doc:\n",
    "    #             self.coll.update_one({key: doc[key]}, {'$set': doc}, upsert=True)\n",
    "    #         else:\n",
    "    #             raise ValueError(f\"Key '{key}' not found in document.\")\n",
    "    #     lg.info(f\"Updated {len(docs)} documents in {self.ds_name} collection.\")\n",
    "    #     return True\n",
    "\n",
    "\n",
    "\n",
    "    # def insert_one(self, doc):\n",
    "    #     \"\"\"Insert a single document into the connected collection\"\"\"\n",
    "    #     if not hasattr(self, 'coll'):\n",
    "    #         lg.error(\"No collection connected. Please call connect() first.\")\n",
    "    #         return None\n",
    "    #     self.coll.insert_one(doc)\n",
    "    #     lg.info(f\"Inserted document into {self.ds_name} collection.\")\n",
    "    #     return True\n",
    "    def __enter__(self):\n",
    "        \"\"\"Called when entering the 'with' statement.\"\"\"\n",
    "        lg.debug(\"Entering context...\")\n",
    "        return self # Return the instance to be used in the 'with' block\n",
    "    \n",
    "    def __exit__(self,*args):\n",
    "        \"\"\"Called when exiting the 'with' statement.\"\"\"\n",
    "        # This method is always called, ensuring the connection is closed.\n",
    "        self.close()\n",
    "        # lg.debug(\"MongoClient connection closed.\")\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Explicitly close the mongo client connection\"\"\"  \n",
    "        if self.closing:\n",
    "            return\n",
    "        try:\n",
    "            self.closing = True\n",
    "            if hasattr(self, 'mongo_client'):\n",
    "                lg.debug(\"checking for mongoclient\")\n",
    "                self.mongo_client.close()\n",
    "                lg.info(\"MongoDB client connection closed successfully.\")\n",
    "            else:\n",
    "                lg.debug(\"MongoDB client was not initialized; no connection to close.\")\n",
    "        except Exception as e:\n",
    "            lg.error(f\"Error closing MongoDB client connection: {e}\")\n",
    "    \n",
    "    def __del__(self):\n",
    "        try:\n",
    "            if self.closing:\n",
    "                return\n",
    "            self.close()\n",
    "            lg.debug(\"MongoDB connection closed successfully.\")\n",
    "        except Exception as e:\n",
    "            lg.error(str(e))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfb3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "# %% TESTING\n",
    "# db=IrisDB()\n",
    "# # print(db.find_ds('casia-v1'))\n",
    "# db.list_ds()\n",
    "# db[\"meta\"]\n",
    "# # db.update(\n",
    "# #     {\n",
    "# #         'ds_id': db.find_ds('casia_v1'),\n",
    "# #         'specs': {\n",
    "# #             'num_eyes_per_person': 1\n",
    "# #         }\n",
    "# #     }\n",
    "# # )\n",
    "# # print(db.connect('casiav3'))\n",
    "# # sleep(1)\n",
    "# db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9f8fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_casia_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da78dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "with IrisDB() as db:\n",
    "    # Use the db object to interact with the database\n",
    "    meta=db['meta']\n",
    "    print(db.list_ds())\n",
    "    # db.update(metadata_casia_v1)\n",
    "    # db.insert(metadata_casia_v1)\n",
    "    # print(db.update({\n",
    "    #     'ds_id': db.find_ds('casia-v1'),\n",
    "    #     'injested_at': datetime.now()\n",
    "    # }))\n",
    "    # meta.update_one({'ds_id': db.find_ds('casia-v1')},\n",
    "    #     {\n",
    "    #         '$set':{\n",
    "    #         'ds_id': db.find_ds('casia-v1'),\n",
    "    #         'injested_at': datetime.now()\n",
    "    #         }\n",
    "    #     }\n",
    "    # )\n",
    "    # print(db.find_ds('cas'))\n",
    "    # meta.create_index([('ds_id', 1)], unique=True)\n",
    "    # db.update_data(\n",
    "    #     [{\n",
    "    #         \"ds_id\": db.find_ds('casia-v1'),\n",
    "    #         'orig_base': ORIG_DB_BASE_.as_posix(),\n",
    "    #         'base': DS_BASE_.as_posix()\n",
    "    #     }],\n",
    "    #     key='ds_id'\n",
    "    # )\n",
    "    # print(db.mongo_conn[db.meta_coll].find({}, {'_id': 0, 'ds_id': 1}))\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1d291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Working on uploading CASIA_v1 data to CASIA_v1 collection as well as making a copy of each image in the BASE_ path inside BASE_/orig/\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db7c67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bece294f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#%% \n",
    "DS_ID = \"CASIA_v1\"\n",
    "DS_NAME_ = Path(DS_ID)\n",
    "DS_BASE_ = DB_BASE_ / DS_NAME_\n",
    "fm.ensure_exists(DS_BASE_)\n",
    "\n",
    "ORIG_DB_BASE_ = Path(\"~/datasets/iris_datasets/CASIA/V1/CASIA-IrisV1/CASIA-IrisV1/CASIA Iris Image Database (version 1.0)\").expanduser()\n",
    "\n",
    "images = list(ORIG_DB_BASE_.rglob(\"*.bmp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06f047ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334cc02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[]\n",
    "# with IrisDB() as db:\n",
    "db = IrisDB('casia-v1')\n",
    "ds_id = db.find_ds('casia-v1')\n",
    "meta_doc = db.meta_coll.find_one({'ds_id': ds_id})\n",
    "try:\n",
    "    db.coll.create_index([(\"image_id\", ASCENDING)], unique=True)\n",
    "    # create a \n",
    "    db.coll.create_index([(\"person_id\",ASCENDING)])\n",
    "    db.coll.create_index([(\"eye_id\",ASCENDING)])\n",
    "\n",
    "    # index status which can be one of 'orig','norm','segm'\n",
    "    # db.coll.create_index([(\"status\",ASCENDING)])\n",
    "    # index path as well\n",
    "    db.coll.create_index([(\"paths.rel_path_\",ASCENDING)],unique=True)\n",
    "    # db.coll.create_index([(\"paths.common_path_\",ASCENDING)],unique=True)\n",
    "    # db.coll.create_index([(\"paths.full_path_\",ASCENDING)],unique=True)\n",
    "    # db.coll.create_index([(\"person_id\",ASCENDING),(\"person_sample_id\",ASCENDING)],unique=True)\n",
    "    # db.coll.create_index([(\"eye_id\",ASCENDING),(\"sample_id\",ASCENDING)],unique=True)\n",
    "except Exception as e:\n",
    "    lg.error(f\"Error creating indexes for {ds_id} collection: {e}\")\n",
    "for img in test:\n",
    "    person_id,session_id,sample_id = map(int, img.stem.split(\"_\"))\n",
    "    eye = \"L\"\n",
    "    eye_id = f\"{person_id}_{eye}\"\n",
    "    ext = img.suffix\n",
    "    # renaming the 2nd session images into continuous id_s\n",
    "    if session_id == 2:\n",
    "        sample_id = 3+sample_id\n",
    "    person_sample_id=sample_id # in this case\n",
    "    new_filename_ = Path(f\"{eye_id}_{sample_id}{ext}\")\n",
    "    # status = 'orig'\n",
    "    base_ = DS_BASE_\n",
    "    folder_tags = ['orig']\n",
    "    rel_path_ = eye_id / new_filename_\n",
    "    # orig_path_ = 'orig'/rel_path_\n",
    "    # full_orig_path = DS_BASE_ / orig_path_\n",
    "    # norm_path_ = 'norm'/rel_path_\n",
    "    # full_norm_path_ = DS_BASE_ / norm_path_\n",
    "    # seg_path_ = 'seg'/rel_path_\n",
    "    # full_seg_path_ = DS_BASE_ / seg_path_\n",
    "\n",
    "\n",
    "    paths = {\n",
    "        'base_': str(base_),\n",
    "        'rel_path_': str(rel_path_),\n",
    "        # 'orig_path_': str(orig_path_),\n",
    "        # 'full_orig_path_': str(full_orig_path),\n",
    "        # 'norm_path_': str(norm_path_),\n",
    "        # 'full_norm_path_': str(full_norm_path_),\n",
    "        # 'seg_path_': str(seg_path_),\n",
    "        # 'full_seg_path_': str(full_seg_path_)\n",
    "    }\n",
    "    \n",
    "    orig_paths = {\n",
    "        'base_': str(ORIG_DB_BASE_),\n",
    "        'rel_path_': str(img.relative_to(ORIG_DB_BASE_)),\n",
    "        'orig_path_': str(img),\n",
    "    }\n",
    "    \n",
    "    doc = {\n",
    "        'ds_id': ds_id,\n",
    "        'person_id': str(person_id),\n",
    "        'eye_id': eye_id,  # only one eye per person in this dataset\n",
    "        'sample_id': str(sample_id),\n",
    "        'person_sample_id': str(person_sample_id),\n",
    "        'image_id': str(new_filename_.stem),\n",
    "        'file_name': str(new_filename_),\n",
    "        'session_id': str(session_id),\n",
    "        # 'status': status,\n",
    "        'eye': eye,\n",
    "        'img_specs': meta_doc['img_specs'],\n",
    "        'paths': paths,\n",
    "        'orig_paths': orig_paths,\n",
    "        'injested_at': datetime.now()\n",
    "    }\n",
    "    # docs.append(doc)\n",
    "    db.insert(doc)\n",
    "    fm.copy_file(img, base_ / 'orig' / new_filename_)\n",
    "\n",
    "# db.insert(docs)\n",
    "db.close()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iris-db",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
